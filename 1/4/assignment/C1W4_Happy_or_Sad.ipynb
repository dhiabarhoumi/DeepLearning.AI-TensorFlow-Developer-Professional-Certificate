{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvJbBW_oDOwC"
   },
   "source": [
    "# Week 4: Handling Complex Images - Happy or Sad Dataset\n",
    "\n",
    "In this assignment you will be using the happy or sad dataset, which contains 80 images of emoji-like faces, 40 happy and 40 sad.\n",
    "\n",
    "Create a convolutional neural network that trains to 100% accuracy on these images,  which cancels training upon hitting training accuracy of >.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NFuMFYXtwsT",
    "outputId": "723d6bc3-c7cd-491b-d6f8-49a2e404a0a2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by taking a look at some images of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "uaWTfp5Ox9E-",
    "outputId": "1a4b4b15-9a5f-4fd3-8c56-b32d47ae0893"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "happy_dir=\"./data/happy\"\n",
    "sad_dir=\"./data/sad\"\n",
    "\n",
    "plt.imshow(load_img(f\"{os.path.join(happy_dir,os.listdir(happy_dir)[0])}\"))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(load_img(f\"{os.path.join(sad_dir,os.listdir(sad_dir)[0])}\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is cool to be able to see examples of the images to better understand the problem-space you are dealing with. \n",
    "\n",
    "However there is still some relevant information that is missing such as the resolution of the image (although matplotlib renders the images in a grid providing a good idea of these values) and the maximum pixel value (this is important for normalizing these values). For this you can use Keras as shown in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "sample_img=load_img(os.path.join(happy_dir,os.listdir(happy_dir)[0]))\n",
    "sample_array=img_to_array(sample_img)\n",
    "\n",
    "print(f\"image has shape{sample_array.shape}\")\n",
    "print(f\"max pixel value : {np.max(sample_array)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the images have a resolution of 150x150. **This is very important because this will be the input size of the first layer in your network.** \n",
    "\n",
    "**The last dimension refers to each one of the 3 RGB channels that are used to represent colored images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0UOFLauzIW4"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epochs,logs=[]):\n",
    "        if logs.get('accuracy')>0.999 and logs.get('accuracy') is not None:\n",
    "            print(\"reached 99.9% accuracy\")\n",
    "            self.model.stop_training=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note on callbacks: \n",
    "\n",
    "So far you have used only the `on_epoch_end` callback but there are many more. For example you might want to check out the [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) callback, which allows you to save the best weights for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides great support for preprocessing image data. A lot can be accomplished by using the `ImageDataGenerator` class. Be sure to check out the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) if you get stuck in the next exercise. In particular you might want to pay attention to the `rescale` argument when instantiating the `ImageDataGenerator` and to the [`flow_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "rrGO8ObGzqht"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def image_generator():\n",
    "\n",
    "    train_data=ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "    train_generator=train_data.flow_from_directory(directory='./data/',tagret_size=(150,150),batch_size=10,class_mode='binary')\n",
    "    return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9uxJFQb1nOx",
    "outputId": "0c6ce535-7764-4bc0-a4a4-e6289a360b04"
   },
   "outputs": [],
   "source": [
    "generated=image_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Found 80 images belonging to 2 classes.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUcNTpra1FK0"
   },
   "outputs": [],
   "source": [
    "def train_happy_sad_model(train_gen):\n",
    "    callbacks=myCallback()\n",
    "\n",
    "\n",
    "    model=tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    history=model.fit(train_gen,epochs=20,callbacks=[callbacks])\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSaPPUe_z_OU",
    "outputId": "b6e6306a-8b28-463b-e1a0-8bdeb9116f26"
   },
   "outputs": [],
   "source": [
    "hist = train_happy_sad_model(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the message that was defined in the callback printed out after less than 15 epochs it means your callback worked as expected and training was successful. You can also double check by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0imravDn0Ajz"
   },
   "outputs": [],
   "source": [
    "print(f\"Your model reached the desired accuracy after {len(hist.epoch)} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing the last assignment of this course!**\n",
    "\n",
    "You have successfully implemented a CNN to assist you in the classification task for complex images. Nice job!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
